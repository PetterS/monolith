// Petter Strandmark 2012â€“2013.

#include <algorithm>
#include <exception>
#include <iomanip>
#include <iostream>
#include <stdexcept>
#include <typeinfo>
#include <unordered_set>

#ifdef USE_OPENMP
#include <omp.h>
#endif

#include <absl/container/flat_hash_set.h>

#include <minimum/core/check.h>
#include <minimum/core/time.h>
#include <minimum/nonlinear/function.h>
using minimum::core::check;
using minimum::core::wall_time;

namespace minimum {
namespace nonlinear {

// These two structs are used by Function to store added
// variables and terms.
struct AddedVariable {
	int user_dimension;    // The dimension the Term object sees for evaluation.
	int solver_dimension;  // The dimension of the variables the solver sees.
	double* user_data;     // The pointer provided by the user.
	size_t global_index;   // Global index into a vector of all scalars.
	bool is_constant;      // Whether this variable is (currently) constant.
	std::shared_ptr<ChangeOfVariables> change_of_variables;
	mutable std::vector<double> temp_space;  // Used internally during evaluation.

	std::vector<Interval<double>> bounds;
};

struct IntPairHash {
	size_t operator()(const std::pair<int, int>& p) const {
		// http://stackoverflow.com/questions/738054/hash-function-for-a-pair-of-long-long
		std::hash<int> hash;
		size_t seed = hash(p.first);
		return hash(p.second) + 0x9e3779b9 + (seed << 6) + (seed >> 2);
	}
};

namespace {
bool is_real(double value) {
	if (value != value) {
		return false;
	} else if (value == std::numeric_limits<double>::infinity()) {
		return false;
	} else if (value == -std::numeric_limits<double>::infinity()) {
		return false;
	} else {
		return true;
	}
}
}  // namespace

class Function::Implementation {
   public:
	Implementation(Function* function_interface);

	// Implemenations of functions in the public interface.
	double evaluate(const Eigen::VectorXd& x,
	                Eigen::VectorXd* gradient,
	                Eigen::MatrixXd* hessian) const;
	double evaluate(const Eigen::VectorXd& x,
	                Eigen::VectorXd* gradient,
	                Eigen::SparseMatrix<double>* hessian) const;
	Interval<double> evaluate(const std::vector<Interval<double>>& x) const;

	// Adds a variable to the function. All variables must be added
	// before any terms containing them are added.
	void add_variable_internal(double* variable,
	                           int dimension,
	                           std::shared_ptr<ChangeOfVariables> change_of_variables = 0);

	void set_constant(double* variable, bool is_constant);

	// Copies variables from a global vector x to the Function's
	// local storage.
	void copy_global_to_local(const Eigen::VectorXd& x) const;
	// Copies variables from a global vector x to the storage
	// provided by the user.
	void copy_global_to_user(const Eigen::VectorXd& x) const;
	// Copies variables from a the storage provided by the user
	// to a global vector x.
	void copy_user_to_global(Eigen::VectorXd* x) const;
	// Copies variables from a the storage provided by the user
	// to the Function's local storage.
	void copy_user_to_local() const;

	// Evaluates the function at the point in the local storage.
	double evaluate_from_local_storage() const;

	// Clears the function to the empty function.
	void clear();

	// All variables added to the function.
	std::vector<AddedVariable> variables;
	std::map<double*, std::size_t> variables_map;

	// Each variable can have several dimensions. This member
	// keeps track of the total number of scalars.
	size_t number_of_scalars;
	size_t number_of_constants;

	// Constant term (default: 0)
	double constant;

	// All terms added to the function.
	std::vector<AddedTerm> terms;

	// Number of threads used for evaluation.
	int number_of_threads;

	// Allocates temporary storage for gradient evaluations.
	// Should be called automatically at first evaluate()
	void allocate_local_storage() const;

	// If finalize has been called.
	mutable bool local_storage_allocated;
	// Has to be mutable because the temporary storage
	// needs to be written to.
	mutable std::vector<std::vector<Eigen::VectorXd>> thread_gradient_scratch;
	mutable std::vector<Eigen::VectorXd> thread_gradient_storage;
	// Temporary storage for the hessian.
	typedef std::vector<std::vector<Eigen::MatrixXd>> HessianStorage;
	mutable std::vector<HessianStorage> thread_hessian_scratch;
	mutable std::vector<Eigen::MatrixXd> thread_dense_hessian_storage;

	typedef std::vector<Eigen::Triplet<double>> SparseHessianStorage;
	mutable std::vector<SparseHessianStorage> thread_sparse_hessian_storage;

	// Stored how many element were used the last time the Hessian
	// was created.
	mutable size_t number_of_hessian_elements;

	Function* interface;
};

Function::Function() : impl{new Function::Implementation{this}} {}

Function::Function(const Function& org) : impl{new Function::Implementation{this}} { *this = org; }

Function::Implementation::Implementation(Function* function_interface)
    : interface{function_interface} {
	clear();
}

Function::~Function() { delete impl; }

void Function::Implementation::clear() {
	constant = 0;

	terms.clear();
	variables.clear();
	variables_map.clear();
	number_of_scalars = 0;
	number_of_constants = 0;

	thread_gradient_scratch.clear();
	thread_gradient_storage.clear();
	local_storage_allocated = false;

	number_of_hessian_elements = 0;

#ifdef USE_OPENMP
	number_of_threads = omp_get_max_threads();
#else
	number_of_threads = 1;
#endif
}

Function& Function::operator=(const Function& org) {
	if (this == &org) {
		return *this;
	}
	impl->clear();

	this->hessian_is_enabled = org.hessian_is_enabled;
	impl->constant = org.impl->constant;

	// TODO: respect global order.
	std::map<size_t, double*> user_variables;
	for (const auto& added_variable : org.impl->variables_map) {
		AddedVariable& var_info = org.impl->variables[added_variable.second];

		impl->add_variable_internal(
		    added_variable.first, var_info.user_dimension, var_info.change_of_variables);
		user_variables[var_info.global_index] = added_variable.first;
	}
	minimum_core_assert(org.impl->variables.size() == user_variables.size());
	minimum_core_assert(get_number_of_variables() == org.get_number_of_variables());
	minimum_core_assert(get_number_of_scalars() == org.get_number_of_scalars());

	for (const auto& added_term : org.impl->terms) {
		std::vector<double*> vars;
		for (auto var : added_term.added_variables_indices) {
			auto index = org.impl->variables[var].global_index;
			minimum_core_assert(user_variables.find(index) != user_variables.end());
			vars.push_back(user_variables[index]);
		}
		this->add_term(added_term.term, vars);
	}
	minimum_core_assert(org.impl->variables.size() == user_variables.size());

	return *this;
}

Function& Function::operator+=(const Function& org) {
	impl->constant += org.impl->constant;

	// Check that there are no change of variables involved.
	for (const auto& added_variable : org.impl->variables) {
		minimum_core_assert(!added_variable.change_of_variables);
	}
	for (const auto& added_variable : impl->variables) {
		minimum_core_assert(!added_variable.change_of_variables);
	}

	// TODO: respect global order.
	std::map<size_t, double*> user_variables;
	for (const auto& added_variable : org.impl->variables_map) {
		AddedVariable& var_info = org.impl->variables[added_variable.second];

		// No-op if the variable already exists.
		impl->add_variable_internal(
		    added_variable.first, var_info.user_dimension, var_info.change_of_variables);
		user_variables[var_info.global_index] = added_variable.first;
	}

	for (auto const& added_term : org.impl->terms) {
		std::vector<double*> vars;
		for (auto var : added_term.added_variables_indices) {
			auto index = org.impl->variables[var].global_index;
			minimum_core_assert(user_variables.find(index) != user_variables.end());
			vars.push_back(user_variables[index]);
		}
		this->add_term(added_term.term, vars);
	}

	return *this;
}

Function& Function::operator+=(double constant_value) {
	impl->constant += constant_value;
	return *this;
}

void Function::add_variable(double* variable, int dimension) {
	impl->add_variable_internal(variable, dimension);
}

size_t Function::get_variable_global_index(double* variable) const {
	// Find the variable. This has to succeed.
	auto itr = impl->variables_map.find(variable);
	check(itr != impl->variables_map.end(),
	      "Function::get_variable_global_index: variable not found.");

	return impl->variables[itr->second].global_index;
}

size_t Function::get_number_of_variables() const { return impl->variables.size(); }

// Returns the current number of scalars the function contains.
// (each variable contains of one or several scalars.)
size_t Function::get_number_of_scalars() const { return impl->number_of_scalars; }

void Function::add_variable_internal(double* variable,
                                     int dimension,
                                     std::shared_ptr<ChangeOfVariables> change_of_variables) {
	impl->add_variable_internal(variable, dimension, change_of_variables);
}

template <typename Map, typename T>
std::pair<typename Map::const_iterator, typename Map::const_iterator> find_surrounding_elements(
    const Map& map, const T& t) {
	std::pair<typename Map::const_iterator, typename Map::const_iterator> output;
	if (map.empty()) {
		return std::make_pair(map.end(), map.end());
	}

	auto upper = map.upper_bound(t);
	output.second = upper;
	output.first = upper;
	if (upper != map.begin()) output.first--;

	if (output.first->first >= t) {
		output.first = map.end();
	}
	if (output.second != map.end() && output.second->first <= t) {
		output.second = map.end();
	}
	return output;
}

void Function::Implementation::add_variable_internal(
    double* variable, int dimension, std::shared_ptr<ChangeOfVariables> change_of_variables) {
	this->local_storage_allocated = false;

	// Check if variable already exists, and if it
	// does, that it still has the same dimensions.
	auto itr = variables_map.find(variable);
	if (itr != variables_map.end()) {
		AddedVariable& var_info = variables[itr->second];

		check(var_info.user_dimension == dimension,
		      "Function::add_variable: dimension mismatch "
		      "with previously added variable.");

		var_info.change_of_variables = change_of_variables;
		if (change_of_variables) {
			check(var_info.user_dimension == change_of_variables->x_dimension(),
			      "Function::add_variable: x_dimension can not change.");
			check(var_info.solver_dimension == change_of_variables->t_dimension(),
			      "Function::add_variable: t_dimension can not change.");
		}

		return;
	} else if (!variables_map.empty()) {
		// The variable does not yet exist, check that
		// it does not overlap any other.
		auto elems = find_surrounding_elements(variables_map, variable);

		auto succ = elems.second;
		if (succ != variables_map.end()) {
			check(variable + dimension <= variables[succ->second].user_data, "Variables overlap.");
		}

		auto prev = elems.first;
		if (prev != variables_map.end()) {
			const auto& prev_var = variables[prev->second];
			check(prev_var.user_data + prev_var.user_dimension <= variable, "Variables overlap.");
		}
	}

	variables.emplace_back();
	AddedVariable& var_info = variables.back();
	variables_map[variable] = variables.size() - 1;

	var_info.user_data = variable;
	var_info.is_constant = false;
	var_info.change_of_variables = change_of_variables;

	// Set the correct user_dimension and solver_dimension.
	if (change_of_variables) {
		check(dimension == change_of_variables->x_dimension(),
		      "Function::add_variable: dimension does not match the change of variables.");
		var_info.user_dimension = change_of_variables->x_dimension();
		var_info.solver_dimension = change_of_variables->t_dimension();
	} else {
		var_info.user_dimension = dimension;
		var_info.solver_dimension = dimension;
	}

	// Allocate local scratch spaces for evaluation.
	// We need as much space as the dimension of x.
	var_info.temp_space.resize(var_info.user_dimension);
	// Give this variable a global index into a global
	// state vector.
	var_info.global_index = number_of_scalars;
	number_of_scalars += var_info.solver_dimension;
}

void Function::Implementation::set_constant(double* variable, bool is_constant) {
	// Find the variable. This has to succeed.
	auto itr = variables_map.find(variable);
	check(itr != variables_map.end(), "Function::set_constant: variable not found.");

	variables[itr->second].is_constant = is_constant;

	// Recompute all global indices. Expensive!
	this->number_of_scalars = 0;
	for (auto& variable : variables) {
		if (!variable.is_constant) {
			// Give this variable a global index into a global
			// state vector.
			variable.global_index = this->number_of_scalars;
			this->number_of_scalars += variable.solver_dimension;
		}
	}

	this->number_of_constants = 0;
	for (auto& variable : variables) {
		if (variable.is_constant) {
			// Give this variable a global index into a global
			// state vector.
			variable.global_index = this->number_of_scalars + this->number_of_constants;
			this->number_of_constants += variable.solver_dimension;
		}
	}

	this->local_storage_allocated = false;
}

void Function::set_constant(double* variable, bool is_constant) {
	impl->set_constant(variable, is_constant);
}

void Function::add_term(std::shared_ptr<const Term> term, const std::vector<double*>& arguments) {
	impl->local_storage_allocated = false;

	check(term->number_of_variables() == arguments.size(),
	      "Function::add_term: incorrect number of arguments.");

	impl->terms.emplace_back();
	auto& added_term = impl->terms.back();
	added_term.term = term;
	added_term.added_variables_indices.reserve(arguments.size());

	try {
		// Check whether the variables exist.
		for (int var = 0; var < term->number_of_variables(); ++var) {
			auto var_itr = impl->variables_map.find(arguments[var]);
			if (var_itr == impl->variables_map.end()) {
				add_variable(arguments[var], term->variable_dimension(var));
				var_itr = impl->variables_map.find(arguments[var]);
			}
			// The x-dimension of the variable must match what is expected by the term.
			else {
				minimum_core_assert(impl->variables[var_itr->second].user_dimension
				                        == term->variable_dimension(var),
				                    "Function::add_term: variable dimension does not match term.");
			}

			// Look up this variable.
			auto var_index = var_itr->second;
			added_term.added_variables_indices.emplace_back(var_index);
		}
	} catch (...) {
		impl->terms.pop_back();
		throw;
	}
}

size_t Function::get_number_of_terms() const { return impl->terms.size(); }

const BeginEndProvider<AddedTerm> Function::terms() const { return {impl->terms}; }

void Function::set_number_of_threads(int num) {
#ifdef USE_OPENMP
	minimum_core_assert(num > 0,
	                    "Function::set_number_of_threads: "
	                    "invalid number of threads.");
	impl->local_storage_allocated = false;
	impl->number_of_threads = num;
#endif
}

void Function::Implementation::allocate_local_storage() const {
	auto start_time = wall_time();

	size_t max_arity = 1;
	int max_variable_dimension = 1;
	for (const auto& itr : variables) {
		max_variable_dimension = std::max(max_variable_dimension, itr.user_dimension);
	}
	for (const auto& term : terms) {
		max_arity = std::max(max_arity, term.added_variables_indices.size());
	}

	this->thread_gradient_scratch.resize(this->number_of_threads);
	this->thread_gradient_storage.resize(this->number_of_threads);
	for (int t = 0; t < this->number_of_threads; ++t) {
		this->thread_gradient_storage[t].resize(number_of_scalars + number_of_constants);
		this->thread_gradient_scratch[t].resize(max_arity);
		for (int var = 0; var < max_arity; ++var) {
			this->thread_gradient_scratch[t][var].resize(max_variable_dimension);
		}
	}

	// Every term should have a pointer to the local space
	// used when evaluating.
	for (auto& added_term : terms) {
		for (auto ind : added_term.added_variables_indices) {
			// Look up this variable.
			auto& added_variable = variables[ind];
			// Stora a pointer to temporary storage for this variable.
			double* temp_space = &added_variable.temp_space[0];
			added_term.temp_variables.push_back(temp_space);
		}
	}

	if (interface->hessian_is_enabled) {
		this->thread_hessian_scratch.resize(this->number_of_threads);
		for (int t = 0; t < this->number_of_threads; ++t) {
			auto& hessian = this->thread_hessian_scratch[t];

			hessian.resize(max_arity);
			for (int var0 = 0; var0 < max_arity; ++var0) {
				hessian[var0].resize(max_arity);
				for (int var1 = 0; var1 < max_arity; ++var1) {
					hessian[var0][var1].resize(max_variable_dimension, max_variable_dimension);
				}
			}
		}
	}

	this->local_storage_allocated = true;

	interface->allocation_time += wall_time() - start_time;
}

void Function::print_timing_information(std::ostream& out) const {
	out << "----------------------------------------------------\n";
	out << "Function evaluations without gradient : " << evaluations_without_gradient << '\n';
	out << "Function evaluations with gradient    : " << evaluations_with_gradient << '\n';
	out << "Function memory allocation time   : " << allocation_time << '\n';
	out << "Function evaluate time            : " << evaluate_time << '\n';
	out << "Function evaluate time (with g/H) : " << evaluate_with_hessian_time << '\n';
	out << "Function write g/H time           : " << write_gradient_hessian_time << '\n';
	out << "Function copy data time           : " << copy_time << '\n';
	out << "----------------------------------------------------\n";
}

double Function::Implementation::evaluate_from_local_storage() const {
	minimum_core_assert(this->local_storage_allocated);

	interface->evaluations_without_gradient++;
	double start_time = wall_time();

	double value = this->constant;
// Go through and evaluate each term.
// OpenMP requires a signed data type as the loop variable.
#ifdef USE_OPENMP
	// Each thread needs to store a specific error.
	std::vector<std::exception_ptr> evaluation_errors(this->number_of_threads);

#pragma omp parallel for reduction(+ : value) \
                                       num_threads(this->number_of_threads) if (terms.size() > 1)
#endif
	// For loop has to be int for OpenMP.
	for (int i = 0; i < terms.size(); ++i) {
#ifdef USE_OPENMP
		// The thread number calling this iteration.
		int t = omp_get_thread_num();
		// We need to catch all exceptions before leaving
		// the loop body.
		try {
#endif

			// Evaluate the term .
			value += terms[i].term->evaluate(&terms[i].temp_variables[0]);

#ifdef USE_OPENMP
			// We need to catch all exceptions before leaving
			// the loop body.
		} catch (...) {
			evaluation_errors[t] = std::current_exception();
		}
#endif
	}

#ifdef USE_OPENMP
	// Now that we are outside the OpenMP block, we can
	// rethrow exceptions.
	for (auto itr = evaluation_errors.begin(); itr != evaluation_errors.end(); ++itr) {
		// VS 2010 does not have conversion to bool or
		// operator !=.
		if (!(*itr == std::exception_ptr())) {
			std::rethrow_exception(*itr);
		}
	}
#endif

	interface->evaluate_time += wall_time() - start_time;
	return value;
}

double Function::evaluate(const Eigen::VectorXd& x) const {
	if (!impl->local_storage_allocated) {
		impl->allocate_local_storage();
	}

	// Copy values from the global vector x to the temporary storage
	// used for evaluating the term.
	impl->copy_global_to_local(x);

	return impl->evaluate_from_local_storage();
}

double Function::evaluate() const {
	if (!impl->local_storage_allocated) {
		impl->allocate_local_storage();
	}

	// Copy the user state to the local storage
	// for evaluation.
	impl->copy_user_to_local();

	return impl->evaluate_from_local_storage();
}

void Function::create_sparse_hessian(Eigen::SparseMatrix<double>* H) const {
	double start_time = wall_time();

	Implementation::SparseHessianStorage hessian_indices;
	absl::flat_hash_set<std::pair<int, int>> hessian_indices_set;
	impl->number_of_hessian_elements = 0;

	for (const auto& added_term : impl->terms) {
		auto& indices = added_term.added_variables_indices;
		auto& term = added_term.term;

		// Put the hessian into the global hessian.
		for (int var0 = 0; var0 < term->number_of_variables(); ++var0) {
			if (!impl->variables[indices[var0]].is_constant) {
				size_t global_offset0 = impl->variables[indices[var0]].global_index;
				for (int var1 = 0; var1 < term->number_of_variables(); ++var1) {
					if (!impl->variables[indices[var1]].is_constant) {
						size_t global_offset1 = impl->variables[indices[var1]].global_index;
						for (size_t i = 0; i < term->variable_dimension(var0); ++i) {
							for (size_t j = 0; j < term->variable_dimension(var1); ++j) {
								int global_i = static_cast<int>(i + global_offset0);
								int global_j = static_cast<int>(j + global_offset1);
								hessian_indices_set.emplace(global_i, global_j);
							}
						}
					}
				}
			}
		}
	}

	hessian_indices.reserve(hessian_indices_set.size());
	for (const auto& ij : hessian_indices_set) {
		hessian_indices.emplace_back(ij.first, ij.second, 1.0);
	}

	impl->number_of_hessian_elements = hessian_indices.size();

	auto n = static_cast<int>(impl->number_of_scalars);
	H->resize(n, n);
	H->setFromTriplets(hessian_indices.begin(), hessian_indices.end());
	H->makeCompressed();

	this->allocation_time += wall_time() - start_time;
}

void Function::Implementation::copy_global_to_local(const Eigen::VectorXd& x) const {
	double start_time = wall_time();

#ifdef USE_OPENMP
#pragma omp parallel for num_threads(this->number_of_threads) if (variables.size() > 1000)
#endif
	for (std::ptrdiff_t i = 0; i < std::ptrdiff_t(variables.size()); ++i) {
		const auto& var = variables[i];

		if (!var.is_constant) {
			if (var.change_of_variables == nullptr) {
				for (int i = 0; i < var.user_dimension; ++i) {
					var.temp_space[i] = x[var.global_index + i];
				}
			} else {
				var.change_of_variables->t_to_x(&var.temp_space[0], &x[var.global_index]);
			}
		} else {
			// This variable is constant and is therefore not
			// present in the global vector x of variables.
			// Copy the constant from the user space instead.
			for (int i = 0; i < var.user_dimension; ++i) {
				var.temp_space[i] = var.user_data[i];
			}
		}
	}

	interface->copy_time += wall_time() - start_time;
}

void Function::copy_user_to_global(Eigen::VectorXd* x) const { impl->copy_user_to_global(x); }

void Function::Implementation::copy_user_to_global(Eigen::VectorXd* x) const {
	double start_time = wall_time();

	x->resize(this->number_of_scalars);
	for (const auto& var : variables) {
		double* data = var.user_data;

		if (!var.is_constant) {
			if (var.change_of_variables == nullptr) {
				for (int i = 0; i < var.user_dimension; ++i) {
					check(is_real(data[i]), "User data is invalid (NaN or infinity).");

					(*x)[var.global_index + i] = data[i];
				}
			} else {
				var.change_of_variables->x_to_t(&(*x)[var.global_index], data);
			}
		}
	}

	interface->copy_time += wall_time() - start_time;
}

void Function::copy_global_to_user(const Eigen::VectorXd& x) const { impl->copy_global_to_user(x); }

void Function::Implementation::copy_global_to_user(const Eigen::VectorXd& x) const {
	double start_time = wall_time();

	for (const auto& var : variables) {
		double* data = var.user_data;

		if (!var.is_constant) {
			if (var.change_of_variables == nullptr) {
				for (int i = 0; i < var.user_dimension; ++i) {
					data[i] = x[var.global_index + i];
				}
			} else {
				var.change_of_variables->t_to_x(data, &x[var.global_index]);
			}
		}
	}

	interface->copy_time += wall_time() - start_time;
}

void Function::Implementation::copy_user_to_local() const {
	double start_time = wall_time();

	for (const auto& var : variables) {
		double* data = var.user_data;

		// Both variables and constants are copied here.

		for (int i = 0; i < var.user_dimension; ++i) {
			check(is_real(data[i]), "User data is invalid (NaN or infinity).");

			var.temp_space[i] = data[i];
		}
	}

	interface->copy_time += wall_time() - start_time;
}

double Function::evaluate(const Eigen::VectorXd& x, Eigen::VectorXd* gradient) const {
	return this->evaluate(x, gradient, reinterpret_cast<Eigen::MatrixXd*>(0));
}

double Function::evaluate(const Eigen::VectorXd& x,
                          Eigen::VectorXd* gradient,
                          Eigen::MatrixXd* hessian) const {
	return impl->evaluate(x, gradient, hessian);
}

double Function::Implementation::evaluate(const Eigen::VectorXd& x,
                                          Eigen::VectorXd* gradient,
                                          Eigen::MatrixXd* hessian) const {
	interface->evaluations_with_gradient++;

	minimum_core_assert(!hessian || interface->hessian_is_enabled,
	                    "Function::evaluate: Hessian computation is not enabled.");

	if (!this->local_storage_allocated) {
		this->allocate_local_storage();
	}

	double start_time = wall_time();
	if (hessian) {
#ifdef USE_OPENMP
		thread_dense_hessian_storage.resize(this->number_of_threads);
#else
		thread_dense_hessian_storage.resize(1);
#endif
		for (int t = 0; t < this->number_of_threads; ++t) {
			thread_dense_hessian_storage[t].resize(static_cast<int>(this->number_of_scalars),
			                                       static_cast<int>(this->number_of_scalars));
			thread_dense_hessian_storage[t].setZero();
		}
	}
	interface->allocation_time += wall_time() - start_time;

	// Copy values from the global vector x to the temporary storage
	// used for evaluating the term.
	this->copy_global_to_local(x);

	start_time = wall_time();

	// Initialize each thread's global gradient.
	for (int t = 0; t < this->number_of_threads; ++t) {
		this->thread_gradient_storage[t].setZero();
	}

	double value = this->constant;

// Go through and evaluate each term.
// OpenMP requires a signed data type as the loop variable.
#ifdef USE_OPENMP
	// Each thread needs to store a specific error.
	std::vector<std::exception_ptr> evaluation_errors(this->number_of_threads);

#pragma omp parallel for reduction(+ : value) num_threads(this->number_of_threads)
#endif
	for (int i = 0; i < terms.size(); ++i) {
#ifdef USE_OPENMP
		// The thread number calling this iteration.
		int t = omp_get_thread_num();
		// We need to catch all exceptions before leaving
		// the loop body.
		try {
#else
		int t = 0;
#endif

			if (hessian) {
				// Evaluate the term and put its gradient and hessian
				// into local storage.
				value += terms[i].term->evaluate(&terms[i].temp_variables[0],
				                                 &this->thread_gradient_scratch[t],
				                                 &this->thread_hessian_scratch[t]);

				const auto& term = terms[i].term;
				const auto& indices = terms[i].added_variables_indices;
				// Put the hessian into the global hessian.
				for (int var0 = 0; var0 < term->number_of_variables(); ++var0) {
					if (!variables[indices[var0]].is_constant) {
						minimum_core_assert(!variables[indices[var0]].change_of_variables,
						                    "Change of variables not supported for Hessians");

						size_t global_offset0 = variables[indices[var0]].global_index;
						for (int var1 = 0; var1 < term->number_of_variables(); ++var1) {
							size_t global_offset1 = variables[indices[var1]].global_index;

							if (!variables[indices[var1]].is_constant) {
								const Eigen::MatrixXd& part_hessian =
								    this->thread_hessian_scratch[t][var0][var1];
								for (int i = 0; i < term->variable_dimension(var0); ++i) {
									for (int j = 0; j < term->variable_dimension(var1); ++j) {
										thread_dense_hessian_storage[t].coeffRef(
										    i + global_offset0, j + global_offset1) +=
										    part_hessian(i, j);
									}
								}
							}
						}
					}
				}

			} else {
				// Evaluate the term and put its gradient into local
				// storage.
				value += terms[i].term->evaluate(&terms[i].temp_variables[0],
				                                 &this->thread_gradient_scratch[t]);
			}

			// Put the gradient from the term into the thread's global gradient.
			const auto& indices = terms[i].added_variables_indices;
			for (int var = 0; var < indices.size(); ++var) {
				if (!variables[indices[var]].is_constant) {
					if (variables[indices[var]].change_of_variables == nullptr) {
						// No change of variables, just copy the gradient.
						size_t global_offset = variables[indices[var]].global_index;
						for (int i = 0; i < variables[indices[var]].user_dimension; ++i) {
							this->thread_gradient_storage[t][global_offset + i] +=
							    this->thread_gradient_scratch[t][var][i];
						}
					} else {
						// Transform the gradient from user space to solver space.
						size_t global_offset = variables[indices[var]].global_index;
						if (global_offset < this->number_of_scalars) {
							variables[indices[var]].change_of_variables->update_gradient(
							    &this->thread_gradient_storage[t][global_offset],
							    &x[global_offset],
							    &this->thread_gradient_scratch[t][var][0]);
						}
					}
				}
			}

#ifdef USE_OPENMP
			// We need to catch all exceptions before leaving
			// the loop body.
		} catch (...) {
			evaluation_errors[t] = std::current_exception();
		}
#endif
	}

#ifdef USE_OPENMP
	// Now that we are outside the OpenMP block, we can
	// rethrow exceptions.
	for (auto itr = evaluation_errors.begin(); itr != evaluation_errors.end(); ++itr) {
		// VS 2010 does not have conversion to bool or
		// operator !=.
		if (!(*itr == std::exception_ptr())) {
			std::rethrow_exception(*itr);
		}
	}
#endif

	interface->evaluate_with_hessian_time += wall_time() - start_time;
	start_time = wall_time();

	// Create the global gradient.
	if (gradient->size() != this->number_of_scalars) {
		gradient->resize(this->number_of_scalars);
	}
	gradient->setZero();
	// Sum the gradients from all different terms.
	for (int t = 0; t < this->number_of_threads; ++t) {
		(*gradient) += this->thread_gradient_storage[t].segment(0, this->number_of_scalars);
	}

	if (hessian) {
		// Create the global (dense) hessian.
		hessian->resize(static_cast<int>(this->number_of_scalars),
		                static_cast<int>(this->number_of_scalars));
		hessian->setZero();
		for (int t = 0; t < this->number_of_threads; ++t) {
			(*hessian) += this->thread_dense_hessian_storage[t];
		}
	}

	interface->write_gradient_hessian_time += wall_time() - start_time;
	return value;
}

double Function::evaluate(const Eigen::VectorXd& x,
                          Eigen::VectorXd* gradient,
                          Eigen::SparseMatrix<double>* hessian) const {
	return impl->evaluate(x, gradient, hessian);
}

double Function::Implementation::evaluate(const Eigen::VectorXd& x,
                                          Eigen::VectorXd* gradient,
                                          Eigen::SparseMatrix<double>* hessian) const {
	interface->evaluations_with_gradient++;

	minimum_core_assert(hessian);
	minimum_core_assert(interface->hessian_is_enabled,
	                    "Function::evaluate: Hessian computation is not enabled.");

	if (!this->local_storage_allocated) {
		this->allocate_local_storage();
	}

	double start_time = wall_time();
#ifdef USE_OPENMP
	thread_sparse_hessian_storage.resize(this->number_of_threads);
#else
	thread_sparse_hessian_storage.resize(1);
#endif
	for (int t = 0; t < this->number_of_threads; ++t) {
		// TODO: Most likely too much space per thread here.
		thread_sparse_hessian_storage[t].reserve(this->number_of_hessian_elements);
		thread_sparse_hessian_storage[t].clear();
	}
	this->number_of_hessian_elements = 0;

	interface->allocation_time += wall_time() - start_time;

	// Copy values from the global vector x to the temporary storage
	// used for evaluating the term.
	this->copy_global_to_local(x);

	start_time = wall_time();

	interface->write_gradient_hessian_time += wall_time() - start_time;
	start_time = wall_time();

	// Initialize each thread's global gradient.
	for (int t = 0; t < this->number_of_threads; ++t) {
		this->thread_gradient_storage[t].setZero();
	}

	double value = this->constant;
// Go through and evaluate each term.
// OpenMP requires a signed data type as the loop variable.
#ifdef USE_OPENMP
	// Each thread needs to store a specific error.
	std::vector<std::exception_ptr> evaluation_errors(this->number_of_threads);

#pragma omp parallel for reduction(+ : value) num_threads(this->number_of_threads)
#endif
	for (int i = 0; i < terms.size(); ++i) {
#ifdef USE_OPENMP
		// The thread number calling this iteration.
		int t = omp_get_thread_num();
		// We need to catch all exceptions before leaving
		// the loop body.
		try {
#else
		int t = 0;
#endif

			// Evaluate the term and put its gradient and hessian
			// into local storage.
			value += terms[i].term->evaluate(&terms[i].temp_variables[0],
			                                 &this->thread_gradient_scratch[t],
			                                 &this->thread_hessian_scratch[t]);

			// Put the gradient from the term into the thread's global gradient.
			const auto& indices = terms[i].added_variables_indices;
			for (int var = 0; var < indices.size(); ++var) {
				if (!variables[indices[var]].is_constant) {
					minimum_core_assert(!variables[indices[var]].change_of_variables,
					                    "Change of variables not supported for sparse Hessian");

					size_t global_offset = variables[indices[var]].global_index;
					for (int i = 0; i < variables[indices[var]].user_dimension; ++i) {
						this->thread_gradient_storage[t][global_offset + i] +=
						    this->thread_gradient_scratch[t][var][i];
					}
				}
			}

			// Put the hessian from the term into the thread's global hessian.
			const auto& term = terms[i].term;
			for (int var0 = 0; var0 < term->number_of_variables(); ++var0) {
				if (!variables[indices[var0]].is_constant) {
					size_t global_offset0 = variables[indices[var0]].global_index;
					for (int var1 = 0; var1 < term->number_of_variables(); ++var1) {
						if (!variables[indices[var1]].is_constant) {
							size_t global_offset1 = variables[indices[var1]].global_index;
							const Eigen::MatrixXd& part_hessian =
							    this->thread_hessian_scratch[t][var0][var1];
							for (int i = 0; i < term->variable_dimension(var0); ++i) {
								for (int j = 0; j < term->variable_dimension(var1); ++j) {
									int global_i = static_cast<int>(i + global_offset0);
									int global_j = static_cast<int>(j + global_offset1);
									thread_sparse_hessian_storage[t].push_back(
									    Eigen::Triplet<double>(
									        global_i, global_j, part_hessian(i, j)));
								}
							}
						}
					}
				}
			}

#ifdef USE_OPENMP
			// We need to catch all exceptions before leaving
			// the loop body.
		} catch (...) {
			evaluation_errors[t] = std::current_exception();
		}
#endif
	}

#ifdef USE_OPENMP
	// Now that we are outside the OpenMP block, we can
	// rethrow exceptions.
	for (auto itr = evaluation_errors.begin(); itr != evaluation_errors.end(); ++itr) {
		// VS 2010 does not have conversion to bool or
		// operator !=.
		if (!(*itr == std::exception_ptr())) {
			std::rethrow_exception(*itr);
		}
	}
#endif

	interface->evaluate_with_hessian_time += wall_time() - start_time;
	start_time = wall_time();

	// Create the global gradient.
	if (gradient->size() != this->number_of_scalars) {
		gradient->resize(this->number_of_scalars);
	}
	gradient->setZero();
	// Sum the gradients from all different terms.
	for (int t = 0; t < this->number_of_threads; ++t) {
		(*gradient) += this->thread_gradient_storage[t].segment(0, this->number_of_scalars);
	}

	for (int t = 1; t < thread_sparse_hessian_storage.size(); ++t) {
		for (const auto& triple : thread_sparse_hessian_storage[t]) {
			thread_sparse_hessian_storage[0].emplace_back(triple);
		}
	}

	hessian->setFromTriplets(thread_sparse_hessian_storage[0].begin(),
	                         thread_sparse_hessian_storage[0].end());
	// hessian->makeCompressed();

	interface->write_gradient_hessian_time += wall_time() - start_time;

	return value;
}

Interval<double> Function::evaluate(const std::vector<Interval<double>>& x) const {
	return impl->evaluate(x);
}

Interval<double> Function::Implementation::evaluate(const std::vector<Interval<double>>& x) const {
	if (!this->local_storage_allocated) {
		this->allocate_local_storage();
	}
	// Copies constant variables.
	this->copy_user_to_local();

	minimum_core_assert(x.size() == this->number_of_scalars);

	interface->evaluations_without_gradient++;
	double start_time = wall_time();

	std::vector<std::vector<const Interval<double>*>> scratch_space;
	std::vector<std::vector<std::vector<Interval<double>>>> temp_intervals;
#ifdef USE_OPENMP
	scratch_space.resize(this->number_of_threads);
	temp_intervals.resize(this->number_of_threads);
#else
	scratch_space.resize(1);
	temp_intervals.resize(1);
#endif

	double lower = this->constant;
	double upper = this->constant;

#ifdef USE_OPENMP
	// Each thread needs to store a specific error.
	std::vector<std::exception_ptr> evaluation_errors(this->number_of_threads);

// Go through and evaluate each term.
// reduction(+ : lower) reduction(+ : upper)
#pragma omp parallel for reduction(+ : lower) reduction(+ : upper) num_threads( \
    this->number_of_threads) if (terms.size() > 1)
#endif
	for (int i = 0; i < terms.size(); ++i) {
		// Evaluate each term.

#ifdef USE_OPENMP
		int t = omp_get_thread_num();

		// We need to catch all exceptions before leaving
		// the loop body.
		try {
#else
		int t = 0;
#endif

			temp_intervals[t].clear();
			scratch_space[t].clear();
			for (auto var : terms[i].added_variables_indices) {
				if (variables[var].is_constant) {
					// This code assumes that vectors that are part of another
					// vector are not reallocated when the outer vector is
					// resized. This is true if std::move of a vector is
					// implemented without reallocation.
					temp_intervals[t].emplace_back();
					for (auto value : variables[var].temp_space) {
						temp_intervals[t].back().emplace_back(value, value);
					}
					scratch_space[t].push_back(temp_intervals[t].back().data());
				} else {
					check(variables[var].change_of_variables == nullptr,
					      "Global optimization does not support change of variables.");

					auto global_index = variables[var].global_index;
					scratch_space[t].push_back(&x.at(global_index));
				}
			}

			auto value = terms[i].term->evaluate_interval(scratch_space[t].data());
			lower += value.get_lower();
			upper += value.get_upper();

#ifdef USE_OPENMP
			// We need to catch all exceptions before leaving
			// the loop body.
		} catch (...) {
			evaluation_errors[t] = std::current_exception();
		}
#endif
	}

#ifdef USE_OPENMP
	// Now that we are outside the OpenMP block, we can
	// rethrow exceptions.
	for (auto itr = evaluation_errors.begin(); itr != evaluation_errors.end(); ++itr) {
		// VS 2010 does not have conversion to bool or
		// operator !=.
		if (!(*itr == std::exception_ptr())) {
			std::rethrow_exception(*itr);
		}
	}
#endif

	Interval<double> value(lower, upper);
	interface->evaluate_time += wall_time() - start_time;
	return value;
}

void Function::write_to_stream(std::ostream& out) const {
	using namespace std;

	// Use high precision.
	out << setprecision(30);

	// Write version to stream;
	out << "minimum::nonlinear::function" << endl;
	out << 1 << endl;
	// Write the representation of a reasonably complicated class to
	// the file. We can then check that the compiler-dependent format
	// matches.
	out << TermFactory::fix_name(typeid(std::vector<std::map<double, int>>).name()) << endl;

	out << impl->terms.size() << endl;
	out << impl->variables.size() << endl;
	out << impl->number_of_scalars << endl;
	out << impl->constant << endl;

	vector<pair<std::size_t, std::size_t>> variable_dimensions;
	for (const auto& variable : impl->variables) {
		minimum_core_assert(variable.change_of_variables == nullptr,
		                    "Function::write_to_stream: Change of variables not allowed.");

		variable_dimensions.emplace_back(variable.global_index, variable.user_dimension);
	}
	sort(variable_dimensions.begin(), variable_dimensions.end());
	for (const auto& variable : variable_dimensions) {
		out << variable.second << " ";
	}
	out << endl;

	Eigen::VectorXd x;
	this->copy_user_to_global(&x);
	for (int i = 0; i < impl->number_of_scalars; ++i) {
		out << x[i] << " ";
	}
	out << endl;

	for (const auto& added_term : impl->terms) {
		string term_name = TermFactory::fix_name(typeid(*added_term.term).name());
		out << term_name << endl;
		out << added_term.added_variables_indices.size() << endl;
		for (auto global_index : added_term.added_variables_indices) {
			out << global_index << " ";
		}
		out << endl;
		out << *added_term.term << endl;
	}
}

void Function::read_from_stream(std::istream& in,
                                std::vector<double>* user_space,
                                const TermFactory& factory) {
	using namespace std;

	impl->clear();

	auto check = [&in](const char* variable_name) {
		minimum_core_assert(in, "Function::read_from_stream: Reading ", variable_name, " failed.");
	};
#define read_and_check(var) \
	in >> var;              \
	check(#var);  // cout << #var << " = " << var << endl;

	// TODO: Clear f.

	string minimum_nonlinear_function;
	read_and_check(minimum_nonlinear_function);
	minimum_core_assert(minimum_nonlinear_function == "minimum::nonlinear::function");

	int version;
	read_and_check(version);
	string compiler_type_format;
	read_and_check(compiler_type_format);
	if (compiler_type_format
	    != TermFactory::fix_name(typeid(std::vector<std::map<double, int>>).name())) {
		throw runtime_error(
		    "Function::read_from_stream: Type format does not match. "
		    "Files can not be shared between compilers.");
	}

	unsigned number_of_terms;
	read_and_check(number_of_terms);
	unsigned number_of_variables;
	read_and_check(number_of_variables);
	unsigned number_of_scalars;
	read_and_check(number_of_scalars);
	read_and_check(impl->constant);

	user_space->resize(number_of_scalars);
	int current_var = 0;
	for (unsigned i = 0; i < number_of_variables; ++i) {
		int variable_dimension;
		read_and_check(variable_dimension);
		this->add_variable(&user_space->at(current_var), variable_dimension);
		current_var += variable_dimension;
	}
	minimum_core_assert(current_var == number_of_scalars);

	for (unsigned i = 0; i < number_of_scalars; ++i) {
		read_and_check(user_space->at(i));
	}

	for (unsigned i = 0; i < number_of_terms; ++i) {
		std::string term_name;
		read_and_check(term_name);
		unsigned term_vars;
		read_and_check(term_vars);

		std::vector<double*> arguments;
		for (unsigned i = 0; i < term_vars; ++i) {
			int offset;
			read_and_check(offset);
			arguments.push_back(&user_space->at(offset));
		}

		auto term = std::shared_ptr<const Term>(factory.create(term_name, in));
		this->add_term(term, arguments);
	}

#undef read_and_check
}

void Function::set_variable_bounds(double* variable, std::vector<Interval<double>> bounds) {
	auto index_itr = impl->variables_map.find(variable);
	check(index_itr != impl->variables_map.end(), "Variable not found.");
	AddedVariable& added_variable = impl->variables[index_itr->second];
	check(bounds.empty() || added_variable.user_dimension == bounds.size(),
	      "Bounds size must match the variable size or be zero.");
	check(added_variable.change_of_variables == nullptr,
	      "Change of variables can not be used with bounds.");
	added_variable.bounds = std::move(bounds);
}

const std::vector<Interval<double>>& Function::get_variable_bounds(double* variable) const {
	auto index_itr = impl->variables_map.find(variable);
	check(index_itr != impl->variables_map.end(), "Variable not found.");
	AddedVariable& added_variable = impl->variables[index_itr->second];
	return added_variable.bounds;
}

std::vector<Interval<double>> Function::get_all_variable_bounds() const {
	using namespace std;

	vector<Interval<double>> bounds(get_number_of_scalars());

	for (const auto& added_variable : impl->variables) {
		if (added_variable.bounds.empty()) {
			continue;
		}
		minimum_core_assert(added_variable.user_dimension == added_variable.solver_dimension,
		                    "No change of variables allowed.");
		minimum_core_assert(added_variable.bounds.size() == added_variable.user_dimension);
		for (int i = 0; i < added_variable.user_dimension; ++i) {
			bounds[added_variable.global_index + i] = added_variable.bounds[i];
		}
	}
	return bounds;
}
}  // namespace nonlinear
}  // namespace minimum